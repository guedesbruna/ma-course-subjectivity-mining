{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "%run ml_pipeline/__main__.py"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/Users/brunaguedes/opt/anaconda3/envs/smenv/lib/python3.7/site-packages/sklearn/utils/deprecation.py:143: FutureWarning: The sklearn.metrics.classification module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.metrics. Anything that cannot be imported from sklearn.metrics is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      ">> Running vua_format experiment\n",
      ">> Loading data...\n",
      ">> retrieving train/data instances...\n",
      ">> training pipeline naive_bayes_counts\n",
      ">> testing...\n",
      ">> evaluation...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        hate       0.64      0.91      0.75       239\n",
      "      noHate       0.84      0.48      0.61       239\n",
      "\n",
      "    accuracy                           0.69       478\n",
      "   macro avg       0.74      0.69      0.68       478\n",
      "weighted avg       0.74      0.69      0.68       478\n",
      "\n",
      ">> Running vua_format experiment\n",
      ">> Loading data...\n",
      ">> retrieving train/data instances...\n",
      ">> training pipeline naive_bayes_tfidf\n",
      ">> testing...\n",
      ">> evaluation...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        hate       0.63      0.91      0.74       239\n",
      "      noHate       0.83      0.46      0.59       239\n",
      "\n",
      "    accuracy                           0.68       478\n",
      "   macro avg       0.73      0.68      0.67       478\n",
      "weighted avg       0.73      0.68      0.67       478\n",
      "\n",
      ">> Running vua_format experiment\n",
      ">> Loading data...\n",
      ">> retrieving train/data instances...\n",
      ">> training pipeline svm_libsvc_counts\n",
      ">> testing...\n",
      ">> evaluation...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        hate       0.76      0.76      0.76       239\n",
      "      noHate       0.76      0.77      0.76       239\n",
      "\n",
      "    accuracy                           0.76       478\n",
      "   macro avg       0.76      0.76      0.76       478\n",
      "weighted avg       0.76      0.76      0.76       478\n",
      "\n",
      ">> Running vua_format experiment\n",
      ">> Loading data...\n",
      ">> retrieving train/data instances...\n",
      ">> training pipeline svm_libsvc_tfidf\n",
      ">> testing...\n",
      ">> evaluation...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        hate       0.73      0.81      0.77       239\n",
      "      noHate       0.79      0.69      0.74       239\n",
      "\n",
      "    accuracy                           0.75       478\n",
      "   macro avg       0.76      0.75      0.75       478\n",
      "weighted avg       0.76      0.75      0.75       478\n",
      "\n",
      ">> Running vua_format experiment\n",
      ">> Loading data...\n",
      ">> retrieving train/data instances...\n",
      "1914 train sequences\n",
      "478 data sequences\n",
      "Pad sequences (samples x time)\n",
      "train_X shape: (1914, 40)\n",
      "test_X shape: (478, 40)\n",
      ">> testing...\n",
      ">> training pipeline cnn_raw\n",
      "Build model...\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2021-09-19 19:20:25.299551: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-09-19 19:20:25.333726: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7ff0425c4360 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-09-19 19:20:25.333743: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/6\n",
      "60/60 [==============================] - 0s 7ms/step - loss: 0.6605 - accuracy: 0.6306\n",
      "Epoch 2/6\n",
      "60/60 [==============================] - 0s 5ms/step - loss: 0.5257 - accuracy: 0.7466\n",
      "Epoch 3/6\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.3470 - accuracy: 0.8595\n",
      "Epoch 4/6\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.2105 - accuracy: 0.9295\n",
      "Epoch 5/6\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.1025 - accuracy: 0.9687\n",
      "Epoch 6/6\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.0478 - accuracy: 0.9864\n",
      ">> testing...\n",
      ">> evaluation...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.65      0.69       239\n",
      "           1       0.69      0.77      0.72       239\n",
      "\n",
      "    accuracy                           0.71       478\n",
      "   macro avg       0.71      0.71      0.71       478\n",
      "weighted avg       0.71      0.71      0.71       478\n",
      "\n",
      ">> Running vua_format experiment\n",
      ">> Loading data...\n",
      ">> retrieving train/data instances...\n",
      "1914 train sequences\n",
      "478 data sequences\n",
      "Pad sequences (samples x time)\n",
      "train_X shape: (1914, 40)\n",
      "test_X shape: (478, 40)\n",
      ">> testing...\n",
      ">> training pipeline cnn_prep\n",
      "Build model...\n",
      "Epoch 1/6\n",
      "60/60 [==============================] - 0s 5ms/step - loss: 0.6659 - accuracy: 0.6055\n",
      "Epoch 2/6\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.5204 - accuracy: 0.7550\n",
      "Epoch 3/6\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.3594 - accuracy: 0.8516\n",
      "Epoch 4/6\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.2188 - accuracy: 0.9195\n",
      "Epoch 5/6\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.1159 - accuracy: 0.9639\n",
      "Epoch 6/6\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.0692 - accuracy: 0.9801\n",
      ">> testing...\n",
      ">> evaluation...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.78      0.73       239\n",
      "           1       0.75      0.66      0.70       239\n",
      "\n",
      "    accuracy                           0.72       478\n",
      "   macro avg       0.72      0.72      0.72       478\n",
      "weighted avg       0.72      0.72      0.72       478\n",
      "\n",
      ">> Running vua_format experiment\n",
      ">> Loading data...\n",
      ">> retrieving train/data instances...\n",
      ">> training pipeline naive_bayes_counts\n",
      ">> testing...\n",
      ">> evaluation...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         NOT       0.81      0.93      0.87       620\n",
      "         OFF       0.71      0.45      0.55       240\n",
      "\n",
      "    accuracy                           0.79       860\n",
      "   macro avg       0.76      0.69      0.71       860\n",
      "weighted avg       0.78      0.79      0.78       860\n",
      "\n",
      ">> Running vua_format experiment\n",
      ">> Loading data...\n",
      ">> retrieving train/data instances...\n",
      ">> training pipeline naive_bayes_tfidf\n",
      ">> testing...\n",
      ">> evaluation...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         NOT       0.74      1.00      0.85       620\n",
      "         OFF       0.93      0.12      0.21       240\n",
      "\n",
      "    accuracy                           0.75       860\n",
      "   macro avg       0.84      0.56      0.53       860\n",
      "weighted avg       0.80      0.75      0.67       860\n",
      "\n",
      ">> Running vua_format experiment\n",
      ">> Loading data...\n",
      ">> retrieving train/data instances...\n",
      ">> training pipeline svm_libsvc_counts\n",
      ">> testing...\n",
      ">> evaluation...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         NOT       0.82      0.92      0.87       620\n",
      "         OFF       0.70      0.47      0.56       240\n",
      "\n",
      "    accuracy                           0.79       860\n",
      "   macro avg       0.76      0.69      0.71       860\n",
      "weighted avg       0.78      0.79      0.78       860\n",
      "\n",
      ">> Running vua_format experiment\n",
      ">> Loading data...\n",
      ">> retrieving train/data instances...\n",
      ">> training pipeline svm_libsvc_tfidf\n",
      ">> testing...\n",
      ">> evaluation...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         NOT       0.78      0.98      0.87       620\n",
      "         OFF       0.87      0.30      0.45       240\n",
      "\n",
      "    accuracy                           0.79       860\n",
      "   macro avg       0.83      0.64      0.66       860\n",
      "weighted avg       0.81      0.79      0.75       860\n",
      "\n",
      ">> Running vua_format experiment\n",
      ">> Loading data...\n",
      ">> retrieving train/data instances...\n",
      "13240 train sequences\n",
      "860 data sequences\n",
      "Pad sequences (samples x time)\n",
      "train_X shape: (13240, 40)\n",
      "test_X shape: (860, 40)\n",
      ">> testing...\n",
      ">> training pipeline cnn_raw\n",
      "Build model...\n",
      "Epoch 1/6\n",
      "414/414 [==============================] - 2s 4ms/step - loss: 0.5844 - accuracy: 0.7064\n",
      "Epoch 2/6\n",
      "414/414 [==============================] - 2s 4ms/step - loss: 0.4728 - accuracy: 0.7803\n",
      "Epoch 3/6\n",
      "414/414 [==============================] - 2s 4ms/step - loss: 0.3791 - accuracy: 0.8305\n",
      "Epoch 4/6\n",
      "414/414 [==============================] - 2s 4ms/step - loss: 0.2816 - accuracy: 0.8838\n",
      "Epoch 5/6\n",
      "414/414 [==============================] - 2s 4ms/step - loss: 0.1917 - accuracy: 0.9273\n",
      "Epoch 6/6\n",
      "414/414 [==============================] - 2s 4ms/step - loss: 0.1271 - accuracy: 0.9550\n",
      ">> testing...\n",
      ">> evaluation...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.59      0.54       240\n",
      "           1       0.83      0.77      0.80       620\n",
      "\n",
      "    accuracy                           0.72       860\n",
      "   macro avg       0.67      0.68      0.67       860\n",
      "weighted avg       0.74      0.72      0.73       860\n",
      "\n",
      ">> Running vua_format experiment\n",
      ">> Loading data...\n",
      ">> retrieving train/data instances...\n",
      "13240 train sequences\n",
      "860 data sequences\n",
      "Pad sequences (samples x time)\n",
      "train_X shape: (13240, 40)\n",
      "test_X shape: (860, 40)\n",
      ">> testing...\n",
      ">> training pipeline cnn_prep\n",
      "Build model...\n",
      "Epoch 1/6\n",
      "414/414 [==============================] - 2s 4ms/step - loss: 0.5904 - accuracy: 0.7027\n",
      "Epoch 2/6\n",
      "414/414 [==============================] - 2s 4ms/step - loss: 0.4743 - accuracy: 0.7779\n",
      "Epoch 3/6\n",
      "414/414 [==============================] - 2s 4ms/step - loss: 0.3903 - accuracy: 0.8261\n",
      "Epoch 4/6\n",
      "414/414 [==============================] - 2s 4ms/step - loss: 0.2897 - accuracy: 0.8802\n",
      "Epoch 5/6\n",
      "414/414 [==============================] - 2s 4ms/step - loss: 0.1980 - accuracy: 0.9270\n",
      "Epoch 6/6\n",
      "414/414 [==============================] - 2s 4ms/step - loss: 0.1333 - accuracy: 0.9522\n",
      ">> testing...\n",
      ">> evaluation...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.59      0.54       240\n",
      "           1       0.83      0.78      0.80       620\n",
      "\n",
      "    accuracy                           0.73       860\n",
      "   macro avg       0.67      0.68      0.67       860\n",
      "weighted avg       0.74      0.73      0.73       860\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Results for experiments in different datasets"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "#list of all experiments \n",
    "olid_nbc = result['data/OLID_full/levelA/']['naive_bayes_counts'].classification_report\n",
    "olid_nbt = result['data/OLID_full/levelA/']['naive_bayes_tfidf'].classification_report\n",
    "olid_svmc = result['data/OLID_full/levelA/']['svm_libsvc_counts'].classification_report\n",
    "olid_svmt = result['data/OLID_full/levelA/']['svm_libsvc_tfidf'].classification_report\n",
    "olid_cnnr = result['data/OLID_full/levelA/']['cnn_raw'].classification_report\n",
    "olid_cnnp = result['data/OLID_full/levelA/']['cnn_prep'].classification_report"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "gib_nbc = result['data/gibert/']['naive_bayes_counts'].classification_report\n",
    "gib_nbt = result['data/gibert/']['naive_bayes_tfidf'].classification_report\n",
    "gib_svmc = result['data/gibert/']['svm_libsvc_counts'].classification_report\n",
    "gib_svmt = result['data/gibert/']['svm_libsvc_tfidf'].classification_report\n",
    "gib_cnnr = result['data/gibert/']['cnn_raw'].classification_report\n",
    "gib_cnnp = result['data/gibert/']['cnn_prep'].classification_report"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Changing format of datasets to VUA format"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "import pandas as pd \n",
    "\n",
    "data = pd.read_csv ('data/OLID_full/olid-training-v1.0.tsv', sep = '\\t')\n",
    "data.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>subtask_a</th>\n",
       "      <th>subtask_b</th>\n",
       "      <th>subtask_c</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>86426</td>\n",
       "      <td>@USER She should ask a few native Americans wh...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>UNT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>90194</td>\n",
       "      <td>@USER @USER Go home you’re drunk!!! @USER #MAG...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>TIN</td>\n",
       "      <td>IND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16820</td>\n",
       "      <td>Amazon is investigating Chinese employees who ...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>62688</td>\n",
       "      <td>@USER Someone should'veTaken\" this piece of sh...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>UNT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>43605</td>\n",
       "      <td>@USER @USER Obama wanted liberals &amp;amp; illega...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                              tweet subtask_a  \\\n",
       "0  86426  @USER She should ask a few native Americans wh...       OFF   \n",
       "1  90194  @USER @USER Go home you’re drunk!!! @USER #MAG...       OFF   \n",
       "2  16820  Amazon is investigating Chinese employees who ...       NOT   \n",
       "3  62688  @USER Someone should'veTaken\" this piece of sh...       OFF   \n",
       "4  43605  @USER @USER Obama wanted liberals &amp; illega...       NOT   \n",
       "\n",
       "  subtask_b subtask_c  \n",
       "0       UNT       NaN  \n",
       "1       TIN       IND  \n",
       "2       NaN       NaN  \n",
       "3       UNT       NaN  \n",
       "4       NaN       NaN  "
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "trainData = data[[\"id\", \"tweet\", 'subtask_a']]\n",
    "trainData = trainData.rename(columns={\"id\": \"Id\", \"tweet\": \"Text\", \"subtask_a\": \"Label\"})\n",
    "trainData.to_csv('data/OLID_full/levelA/trainData.csv', index=False, sep = '\\t')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "datatest = pd.read_csv ('data/OLID_full/levelA/testData.csv', sep=\";\")\n",
    "datatest.to_csv('data/OLID_full/levelA/testData.csv', index=False, sep = '\\t')"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.11 64-bit ('smenv': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "interpreter": {
   "hash": "e255d92f6cdda4ae4b4a3e668d62e973ca136034d31dfca6f5cbc8e835d9560e"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}